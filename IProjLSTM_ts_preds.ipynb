{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d40cbc",
   "metadata": {},
   "source": [
    "# Data Type I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd988160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04e45a",
   "metadata": {},
   "source": [
    "## IB-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c19796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Encoder\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim + hidden_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, z_dim * 2)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x_t, h_prev):\n",
    "        inp = torch.cat([x_t, h_prev], dim=-1)\n",
    "        stats = self.fc(inp)\n",
    "        mu, logvar = stats.chunk(2, dim=-1)\n",
    "        return mu, logvar\n",
    "\n",
    "# Step 2 : Prior\n",
    "class Prior(nn.Module):\n",
    "    def __init__(self, hidden_dim, z_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, z_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, h_prev):\n",
    "        stats = self.fc(h_prev)\n",
    "        mu, logvar = stats.chunk(2, dim=-1)\n",
    "        return mu, logvar\n",
    "\n",
    "# Step 3 : Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(z_dim + hidden_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2)  \n",
    "        )\n",
    "\n",
    "    def forward(self, z_t, h_prev):\n",
    "        inp = torch.cat([z_t, h_prev], dim=-1)\n",
    "        stats = self.fc(inp)\n",
    "        mu, logvar = stats.chunk(2, dim=-1)\n",
    "        return mu, logvar\n",
    "\n",
    "# Reparameterization trick\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "# Step 4 : RIB_GRU_Model\n",
    "class RIB_GRU_Model(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=64, z_dim=16):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, z_dim)\n",
    "        self.prior = Prior(hidden_dim, z_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim)\n",
    "\n",
    "        self.gru_cell = nn.GRUCell(z_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x_t, h_prev):\n",
    "        # Encoder\n",
    "        mu_enc, logvar_enc = self.encoder(x_t, h_prev)\n",
    "        z_t = reparameterize(mu_enc, logvar_enc)\n",
    "\n",
    "        # Prior\n",
    "        mu_prior, logvar_prior = self.prior(h_prev)\n",
    "\n",
    "        # Decoder\n",
    "        mu_dec, logvar_dec = self.decoder(z_t, h_prev)\n",
    "\n",
    "        # GRU update\n",
    "        h_t = self.gru_cell(z_t, h_prev)\n",
    "\n",
    "        return {\n",
    "            'z_t': z_t,\n",
    "            'mu_enc': mu_enc, 'logvar_enc': logvar_enc,\n",
    "            'mu_prior': mu_prior, 'logvar_prior': logvar_prior,\n",
    "            'mu_dec': mu_dec, 'logvar_dec': logvar_dec,\n",
    "            'h_t': h_t\n",
    "        }\n",
    "    \n",
    "# Loss function\n",
    "LOG_2PI = torch.tensor(np.log(2.0 * np.pi))\n",
    "\n",
    "def rib_loss(outputs, y_t, beta=0.005):\n",
    "    \n",
    "    mu_enc = outputs['mu_enc']\n",
    "    logvar_enc = outputs['logvar_enc']\n",
    "    mu_prior = outputs['mu_prior']\n",
    "    logvar_prior = outputs['logvar_prior']\n",
    "    mu_dec = outputs['mu_dec']\n",
    "    logvar_dec = outputs['logvar_dec']\n",
    "\n",
    "    log_2pi = LOG_2PI.to(y_t.device) \n",
    "\n",
    "    # Decoder Gaussian NLL\n",
    "    var_dec = logvar_dec.exp()\n",
    "    nll = 0.5 * (log_2pi + logvar_dec + ((y_t - mu_dec) ** 2) / var_dec)\n",
    "    recon_loss = nll.mean()\n",
    "\n",
    "    # KL(q || p)\n",
    "    var_enc = logvar_enc.exp()\n",
    "    var_prior = logvar_prior.exp()\n",
    "    kl = 0.5 * torch.sum(logvar_prior - logvar_enc + (var_enc + (mu_enc - mu_prior) ** 2) / var_prior - 1, dim=-1).mean()\n",
    "\n",
    "    return recon_loss + beta * kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9dc573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1000, Test size: 1000\n",
      "Epoch 1/1000 | Train Loss: 1.0913\n",
      "Epoch 100/1000 | Train Loss: -0.4132\n",
      "Epoch 200/1000 | Train Loss: -0.5210\n",
      "Epoch 300/1000 | Train Loss: -1.3404\n",
      "Epoch 400/1000 | Train Loss: -1.4463\n",
      "Epoch 500/1000 | Train Loss: -1.4774\n",
      "Epoch 600/1000 | Train Loss: -1.5172\n",
      "Epoch 700/1000 | Train Loss: -1.5301\n",
      "Epoch 800/1000 | Train Loss: -1.4996\n",
      "Epoch 900/1000 | Train Loss: -1.5180\n",
      "Epoch 1000/1000 | Train Loss: -1.5305\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('data/Sunspots_clean.csv')\n",
    "values = df['Sunspots'].values\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split into training and test sets\n",
    "train_set = scaled_series[:1000]\n",
    "test_set = scaled_series[1000:2000]\n",
    "\n",
    "print (f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "\n",
    "# Ensure the sequences are of the same length\n",
    "X_train = torch.tensor(train_set[:-1]).unsqueeze(0).float()\n",
    "Y_train = torch.tensor(train_set[1:]).unsqueeze(0).float()\n",
    "\n",
    "X_val = torch.tensor(test_set[:-1]).unsqueeze(0).float()\n",
    "Y_val = torch.tensor(test_set[1:]).unsqueeze(0).float()\n",
    "\n",
    "# Create DataLoader for training and validation sets\n",
    "train_loader = DataLoader(TensorDataset(X_train, Y_train), batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, Y_val), batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "rib_gru_model = RIB_GRU_Model(input_dim=1, hidden_dim=32, z_dim=16)\n",
    "optimizer = optim.Adam(rib_gru_model.parameters(), lr=0.001)\n",
    "beta = 0.005\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    rib_gru_model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        h_t = torch.zeros(X_batch.size(0), rib_gru_model.hidden_dim)\n",
    "\n",
    "        loss = 0.0\n",
    "        for t in range(X_batch.size(1)):\n",
    "            x_t = X_batch[:, t].unsqueeze(-1)\n",
    "            y_t = Y_batch[:, t].unsqueeze(-1)\n",
    "\n",
    "            out = rib_gru_model(x_t, h_t)\n",
    "            h_t = out['h_t']\n",
    "\n",
    "            # Compute loss\n",
    "            loss += rib_loss(out, y_t, beta=beta)\n",
    "            \n",
    "        # Average loss over the batch\n",
    "        loss /= X_batch.size(1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    if (epoch + 1) % 100 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 5mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1310bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: RIB-GRU MAE: 0.0462 | RMSE: 0.0643\n",
      "Run 2: RIB-GRU MAE: 0.0468 | RMSE: 0.0651\n",
      "Run 3: RIB-GRU MAE: 0.0467 | RMSE: 0.0656\n",
      "Run 4: RIB-GRU MAE: 0.0471 | RMSE: 0.0666\n",
      "Run 5: RIB-GRU MAE: 0.0478 | RMSE: 0.0661\n",
      "Run 6: RIB-GRU MAE: 0.0466 | RMSE: 0.0654\n",
      "Run 7: RIB-GRU MAE: 0.0468 | RMSE: 0.0650\n",
      "Run 8: RIB-GRU MAE: 0.0462 | RMSE: 0.0649\n",
      "Run 9: RIB-GRU MAE: 0.0471 | RMSE: 0.0657\n",
      "Run 10: RIB-GRU MAE: 0.0473 | RMSE: 0.0665\n",
      "======= FINAL RESULTS =======\n",
      "Mean RIB-GRU MAE: 0.0469 | RMSE: 0.0655\n"
     ]
    }
   ],
   "source": [
    "# Store metrics from all runs\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for run in range(10):\n",
    "\n",
    "    # Validation\n",
    "    rib_gru_model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    vars_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "\n",
    "            h_t = torch.zeros(X_batch.size(0), rib_gru_model.hidden_dim)\n",
    "            pred_mu = []\n",
    "            pred_var = []\n",
    "\n",
    "            for t in range(X_batch.size(1)):\n",
    "\n",
    "                x_t = X_batch[:, t].unsqueeze(-1)\n",
    "                y_t = Y_batch[:, t].unsqueeze(-1)\n",
    "\n",
    "                out = rib_gru_model(x_t, h_t)\n",
    "                h_t = out['h_t']\n",
    "\n",
    "                mu_dec = out['mu_dec']\n",
    "                logvar_dec = out['logvar_dec']\n",
    "\n",
    "                pred_mu.append(mu_dec.squeeze(-1))\n",
    "                pred_var.append(torch.exp(logvar_dec).squeeze(-1))\n",
    "\n",
    "            pred_mu = torch.stack(pred_mu, dim=1) \n",
    "            pred_var = torch.stack(pred_var, dim=1)  \n",
    "\n",
    "            preds.append(pred_mu)\n",
    "            vars_all.append(pred_var)\n",
    "            trues.append(Y_batch)\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).squeeze(0).numpy()\n",
    "    trues = torch.cat(trues, dim=0).squeeze(0).numpy()\n",
    "    vars_all = torch.cat(vars_all, dim=0).squeeze(0).numpy()\n",
    "\n",
    "    # Calculate MAE, RMSE\n",
    "    rib_gru_mae = np.mean(np.abs(preds - trues))\n",
    "    rib_gru_rmse = np.sqrt(np.mean((preds - trues)**2))\n",
    "\n",
    "    mae_list.append(rib_gru_mae)\n",
    "    rmse_list.append(rib_gru_rmse)\n",
    "\n",
    "    print(f\"Run {run+1}: RIB-GRU MAE: {rib_gru_mae:.4f} | RMSE: {rib_gru_rmse:.4f}\")\n",
    "\n",
    "# Compute mean metrics\n",
    "mean_rib_gru_mae = np.mean(mae_list)\n",
    "mean_rib_gru_rmse = np.mean(rmse_list)\n",
    "\n",
    "print(\"======= FINAL RESULTS =======\")\n",
    "print(f\"Mean RIB-GRU MAE: {mean_rib_gru_mae:.4f} | RMSE: {mean_rib_gru_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24466a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb7c759a",
   "metadata": {},
   "source": [
    "## IProjLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "806407d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# IProjLSTMCell helper networks \n",
    "class RefNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(RefNetwork, self).__init__()\n",
    "        self.W_mu = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        self.U_mu = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_sigma = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        self.U_sigma = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x_t, h_prev):\n",
    "        mu_t = self.W_mu(x_t) + self.U_mu(h_prev) \n",
    "        log_sigma2_t = self.W_sigma(x_t) + self.U_sigma(h_prev) \n",
    "        sigma2_t = torch.exp(log_sigma2_t) \n",
    "        return mu_t, sigma2_t\n",
    "\n",
    "# Constraint for I-projection\n",
    "class TargetConstraintNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, learn_sigma=True):\n",
    "        super(TargetConstraintNetwork, self).__init__()\n",
    "        self.W_target = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "        self.U_target = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.learn_sigma = learn_sigma\n",
    "        if learn_sigma: \n",
    "            self.W_sigma_target = nn.Linear(input_dim, hidden_dim, bias=False)\n",
    "            self.U_sigma_target = nn.Linear(hidden_dim, hidden_dim)\n",
    "        else:\n",
    "            self.register_buffer('fixed_sigma2', torch.ones(hidden_dim)) \n",
    "\n",
    "    def forward(self, x_t, h_prev):\n",
    "        mu_t_prime = self.W_target(x_t) + self.U_target(h_prev)\n",
    "        if self.learn_sigma: \n",
    "            log_sigma2_prime = self.W_sigma_target(x_t) + self.U_sigma_target(h_prev)\n",
    "            sigma2_t_prime = torch.exp(log_sigma2_prime)\n",
    "        else:\n",
    "            sigma2_t_prime = self.fixed_sigma2\n",
    "        return mu_t_prime, sigma2_t_prime\n",
    "\n",
    "# Main IProjLSTM Cell \n",
    "class IProjLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.ref_net = RefNetwork(input_dim, hidden_dim)\n",
    "        self.target_net = TargetConstraintNetwork(input_dim, hidden_dim)\n",
    "        self.W_o = nn.Linear(input_dim, hidden_dim)\n",
    "        self.U_o = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x_t, h_prev):\n",
    "        mu_ref, sigma2_ref = self.ref_net(x_t, h_prev) \n",
    "        mu_target, sigma2_target = self.target_net(x_t, h_prev)\n",
    "        mu_proj, sigma2_proj = mu_target, sigma2_ref  # I-projection\n",
    "\n",
    "        # Deterministic cell state\n",
    "        C_t = mu_proj\n",
    "        o_t = torch.sigmoid(self.W_o(x_t) + self.U_o(h_prev))\n",
    "        h_t = o_t * torch.tanh(C_t)\n",
    "        return h_t, C_t\n",
    "\n",
    "# Full model using the custom cell \n",
    "class IProjLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cell = IProjLSTMCell(input_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x_seq):\n",
    "        batch_size = x_seq.size(0)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_dim, device=x_seq.device)\n",
    "        for t in range(self.seq_len):\n",
    "            x_t = x_seq[:, t, :]\n",
    "            h_t, C_t = self.cell(x_t, h_t)[:2]\n",
    "        y_pred = self.output_layer(h_t)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defd55b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1000, Test size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('data/Sunspots_clean.csv')  \n",
    "values = df['Sunspots'].values\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split into training and test sets\n",
    "train_set = scaled_series[:1000]\n",
    "test_set = scaled_series[1000:2000]\n",
    "print(f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "\n",
    "# Dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, series, seq_len=20): \n",
    "        self.series = torch.tensor(series, dtype=torch.float32)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.series) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.series[idx:idx+self.seq_len]\n",
    "        y = self.series[idx+self.seq_len]\n",
    "        return x.unsqueeze(-1), y.unsqueeze(-1)\n",
    "    \n",
    "# Parameters\n",
    "seq_len = 16\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = TimeSeriesDataset(train_set, seq_len)\n",
    "test_dataset = TimeSeriesDataset(test_set, seq_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4dfc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0086\n",
      "Epoch 10/100, Train Loss: 0.0037\n",
      "Epoch 20/100, Train Loss: 0.0037\n",
      "Epoch 30/100, Train Loss: 0.0038\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0037\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0037\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 1 - Test MAE: 0.0466 | Test RMSE: 0.0657\n",
      "\n",
      "=== Run 2/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0254\n",
      "Epoch 10/100, Train Loss: 0.0039\n",
      "Epoch 20/100, Train Loss: 0.0037\n",
      "Epoch 30/100, Train Loss: 0.0038\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0038\n",
      "Epoch 60/100, Train Loss: 0.0038\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0037\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 2 - Test MAE: 0.0469 | Test RMSE: 0.0656\n",
      "\n",
      "=== Run 3/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0160\n",
      "Epoch 10/100, Train Loss: 0.0038\n",
      "Epoch 20/100, Train Loss: 0.0037\n",
      "Epoch 30/100, Train Loss: 0.0038\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0038\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0037\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 3 - Test MAE: 0.0470 | Test RMSE: 0.0653\n",
      "\n",
      "=== Run 4/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0079\n",
      "Epoch 10/100, Train Loss: 0.0038\n",
      "Epoch 20/100, Train Loss: 0.0038\n",
      "Epoch 30/100, Train Loss: 0.0037\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0037\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0037\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 4 - Test MAE: 0.0472 | Test RMSE: 0.0656\n",
      "\n",
      "=== Run 5/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0105\n",
      "Epoch 10/100, Train Loss: 0.0037\n",
      "Epoch 20/100, Train Loss: 0.0038\n",
      "Epoch 30/100, Train Loss: 0.0037\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0037\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0038\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 5 - Test MAE: 0.0468 | Test RMSE: 0.0656\n",
      "\n",
      "=== Run 6/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0264\n",
      "Epoch 10/100, Train Loss: 0.0039\n",
      "Epoch 20/100, Train Loss: 0.0037\n",
      "Epoch 30/100, Train Loss: 0.0037\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0037\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0037\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 6 - Test MAE: 0.0471 | Test RMSE: 0.0653\n",
      "\n",
      "=== Run 7/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0600\n",
      "Epoch 10/100, Train Loss: 0.0039\n",
      "Epoch 20/100, Train Loss: 0.0037\n",
      "Epoch 30/100, Train Loss: 0.0038\n",
      "Epoch 40/100, Train Loss: 0.0038\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0037\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0038\n",
      "Epoch 90/100, Train Loss: 0.0038\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 7 - Test MAE: 0.0477 | Test RMSE: 0.0655\n",
      "\n",
      "=== Run 8/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0160\n",
      "Epoch 10/100, Train Loss: 0.0038\n",
      "Epoch 20/100, Train Loss: 0.0037\n",
      "Epoch 30/100, Train Loss: 0.0038\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0038\n",
      "Epoch 70/100, Train Loss: 0.0038\n",
      "Epoch 80/100, Train Loss: 0.0037\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 8 - Test MAE: 0.0467 | Test RMSE: 0.0654\n",
      "\n",
      "=== Run 9/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0260\n",
      "Epoch 10/100, Train Loss: 0.0038\n",
      "Epoch 20/100, Train Loss: 0.0037\n",
      "Epoch 30/100, Train Loss: 0.0038\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0037\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0037\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0037\n",
      "Run 9 - Test MAE: 0.0469 | Test RMSE: 0.0655\n",
      "\n",
      "=== Run 10/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0192\n",
      "Epoch 10/100, Train Loss: 0.0038\n",
      "Epoch 20/100, Train Loss: 0.0038\n",
      "Epoch 30/100, Train Loss: 0.0037\n",
      "Epoch 40/100, Train Loss: 0.0037\n",
      "Epoch 50/100, Train Loss: 0.0037\n",
      "Epoch 60/100, Train Loss: 0.0037\n",
      "Epoch 70/100, Train Loss: 0.0037\n",
      "Epoch 80/100, Train Loss: 0.0037\n",
      "Epoch 90/100, Train Loss: 0.0037\n",
      "Epoch 100/100, Train Loss: 0.0036\n",
      "Run 10 - Test MAE: 0.0471 | Test RMSE: 0.0655\n",
      "\n",
      "======= FINAL RESULTS =======\n",
      "Mean MAE  : 0.0470\n",
      "Mean RMSE : 0.0655\n"
     ]
    }
   ],
   "source": [
    "# Lists to store metrics for all runs\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for run in range(10):\n",
    "    print(f\"\\n=== Run {run+1}/10 ===\")\n",
    "\n",
    "    # Model setup\n",
    "    iproj_model = IProjLSTMModel(input_dim=1, hidden_dim=32, seq_len=seq_len)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iproj_model = iproj_model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(iproj_model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        iproj_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = iproj_model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    iproj_model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_pred = iproj_model(x_batch)\n",
    "            preds.append(y_pred.cpu())\n",
    "            targets.append(y_batch.cpu())\n",
    "\n",
    "    preds = torch.cat(preds).squeeze().numpy()\n",
    "    targets = torch.cat(targets).squeeze().numpy()\n",
    "\n",
    "    iproj_mae = mean_absolute_error(targets, preds)\n",
    "    iproj_rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "\n",
    "    mae_list.append(iproj_mae)\n",
    "    rmse_list.append(iproj_rmse)\n",
    "\n",
    "    print(f\"Run {run+1} - Test MAE: {iproj_mae:.4f} | Test RMSE: {iproj_rmse:.4f}\")\n",
    "\n",
    "# Compute mean metrics\n",
    "mean_iproj_mae = np.mean(mae_list)\n",
    "mean_iproj_rmse = np.mean(rmse_list)\n",
    "\n",
    "print(\"\\n======= FINAL RESULTS =======\")\n",
    "print(f\"Mean MAE  : {mean_iproj_mae:.4f}\")\n",
    "print(f\"Mean RMSE : {mean_iproj_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0776ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57587d5",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f5c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1, seq_len=20):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x_seq):\n",
    "        out, _ = self.lstm(x_seq)\n",
    "        last_hidden = out[:, -1, :]  # take output at final timestep\n",
    "        y_pred = self.output_layer(last_hidden)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('data/Sunspots_clean.csv')  \n",
    "values = df['Sunspots'].values\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split into training and test sets\n",
    "train_set = scaled_series[:1000]\n",
    "test_set = scaled_series[1000:2000]\n",
    "\n",
    "print (f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "\n",
    "# Dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, series, seq_len=20): \n",
    "        self.series = torch.tensor(series, dtype=torch.float32)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.series) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.series[idx:idx+self.seq_len]\n",
    "        y = self.series[idx+self.seq_len]\n",
    "        return x.unsqueeze(-1), y.unsqueeze(-1)\n",
    "\n",
    "# Parameters\n",
    "seq_len = 16\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = TimeSeriesDataset(train_set, seq_len)\n",
    "test_dataset = TimeSeriesDataset(test_set, seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df85f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1000, Test size: 1000\n",
      "\n",
      "=== Run 1/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0317\n",
      "LSTM Epoch 10/100, Train Loss: 0.0045\n",
      "LSTM Epoch 20/100, Train Loss: 0.0041\n",
      "LSTM Epoch 30/100, Train Loss: 0.0039\n",
      "LSTM Epoch 40/100, Train Loss: 0.0038\n",
      "LSTM Epoch 50/100, Train Loss: 0.0040\n",
      "LSTM Epoch 60/100, Train Loss: 0.0038\n",
      "LSTM Epoch 70/100, Train Loss: 0.0037\n",
      "LSTM Epoch 80/100, Train Loss: 0.0036\n",
      "LSTM Epoch 90/100, Train Loss: 0.0037\n",
      "LSTM Epoch 100/100, Train Loss: 0.0036\n",
      "Run 1 - LSTM MAE: 0.0459 | RMSE: 0.0651\n",
      "\n",
      "=== Run 2/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0500\n",
      "LSTM Epoch 10/100, Train Loss: 0.0052\n",
      "LSTM Epoch 20/100, Train Loss: 0.0041\n",
      "LSTM Epoch 30/100, Train Loss: 0.0041\n",
      "LSTM Epoch 40/100, Train Loss: 0.0039\n",
      "LSTM Epoch 50/100, Train Loss: 0.0038\n",
      "LSTM Epoch 60/100, Train Loss: 0.0038\n",
      "LSTM Epoch 70/100, Train Loss: 0.0036\n",
      "LSTM Epoch 80/100, Train Loss: 0.0037\n",
      "LSTM Epoch 90/100, Train Loss: 0.0037\n",
      "LSTM Epoch 100/100, Train Loss: 0.0036\n",
      "Run 2 - LSTM MAE: 0.0462 | RMSE: 0.0656\n",
      "\n",
      "=== Run 3/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0214\n",
      "LSTM Epoch 10/100, Train Loss: 0.0044\n",
      "LSTM Epoch 20/100, Train Loss: 0.0039\n",
      "LSTM Epoch 30/100, Train Loss: 0.0038\n",
      "LSTM Epoch 40/100, Train Loss: 0.0038\n",
      "LSTM Epoch 50/100, Train Loss: 0.0037\n",
      "LSTM Epoch 60/100, Train Loss: 0.0037\n",
      "LSTM Epoch 70/100, Train Loss: 0.0037\n",
      "LSTM Epoch 80/100, Train Loss: 0.0037\n",
      "LSTM Epoch 90/100, Train Loss: 0.0036\n",
      "LSTM Epoch 100/100, Train Loss: 0.0036\n",
      "Run 3 - LSTM MAE: 0.0457 | RMSE: 0.0638\n",
      "\n",
      "=== Run 4/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0212\n",
      "LSTM Epoch 10/100, Train Loss: 0.0045\n",
      "LSTM Epoch 20/100, Train Loss: 0.0041\n",
      "LSTM Epoch 30/100, Train Loss: 0.0039\n",
      "LSTM Epoch 40/100, Train Loss: 0.0038\n",
      "LSTM Epoch 50/100, Train Loss: 0.0037\n",
      "LSTM Epoch 60/100, Train Loss: 0.0037\n",
      "LSTM Epoch 70/100, Train Loss: 0.0037\n",
      "LSTM Epoch 80/100, Train Loss: 0.0036\n",
      "LSTM Epoch 90/100, Train Loss: 0.0037\n",
      "LSTM Epoch 100/100, Train Loss: 0.0036\n",
      "Run 4 - LSTM MAE: 0.0461 | RMSE: 0.0647\n",
      "\n",
      "=== Run 5/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0699\n",
      "LSTM Epoch 10/100, Train Loss: 0.0054\n",
      "LSTM Epoch 20/100, Train Loss: 0.0042\n",
      "LSTM Epoch 30/100, Train Loss: 0.0041\n",
      "LSTM Epoch 40/100, Train Loss: 0.0039\n",
      "LSTM Epoch 50/100, Train Loss: 0.0039\n",
      "LSTM Epoch 60/100, Train Loss: 0.0038\n",
      "LSTM Epoch 70/100, Train Loss: 0.0038\n",
      "LSTM Epoch 80/100, Train Loss: 0.0037\n",
      "LSTM Epoch 90/100, Train Loss: 0.0037\n",
      "LSTM Epoch 100/100, Train Loss: 0.0036\n",
      "Run 5 - LSTM MAE: 0.0478 | RMSE: 0.0650\n",
      "\n",
      "=== Run 6/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0232\n",
      "LSTM Epoch 10/100, Train Loss: 0.0045\n",
      "LSTM Epoch 20/100, Train Loss: 0.0040\n",
      "LSTM Epoch 30/100, Train Loss: 0.0040\n",
      "LSTM Epoch 40/100, Train Loss: 0.0038\n",
      "LSTM Epoch 50/100, Train Loss: 0.0038\n",
      "LSTM Epoch 60/100, Train Loss: 0.0038\n",
      "LSTM Epoch 70/100, Train Loss: 0.0038\n",
      "LSTM Epoch 80/100, Train Loss: 0.0037\n",
      "LSTM Epoch 90/100, Train Loss: 0.0038\n",
      "LSTM Epoch 100/100, Train Loss: 0.0036\n",
      "Run 6 - LSTM MAE: 0.0460 | RMSE: 0.0649\n",
      "\n",
      "=== Run 7/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0595\n",
      "LSTM Epoch 10/100, Train Loss: 0.0052\n",
      "LSTM Epoch 20/100, Train Loss: 0.0043\n",
      "LSTM Epoch 30/100, Train Loss: 0.0040\n",
      "LSTM Epoch 40/100, Train Loss: 0.0041\n",
      "LSTM Epoch 50/100, Train Loss: 0.0039\n",
      "LSTM Epoch 60/100, Train Loss: 0.0039\n",
      "LSTM Epoch 70/100, Train Loss: 0.0037\n",
      "LSTM Epoch 80/100, Train Loss: 0.0037\n",
      "LSTM Epoch 90/100, Train Loss: 0.0037\n",
      "LSTM Epoch 100/100, Train Loss: 0.0037\n",
      "Run 7 - LSTM MAE: 0.0457 | RMSE: 0.0648\n",
      "\n",
      "=== Run 8/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0243\n",
      "LSTM Epoch 10/100, Train Loss: 0.0043\n",
      "LSTM Epoch 20/100, Train Loss: 0.0039\n",
      "LSTM Epoch 30/100, Train Loss: 0.0040\n",
      "LSTM Epoch 40/100, Train Loss: 0.0038\n",
      "LSTM Epoch 50/100, Train Loss: 0.0038\n",
      "LSTM Epoch 60/100, Train Loss: 0.0038\n",
      "LSTM Epoch 70/100, Train Loss: 0.0038\n",
      "LSTM Epoch 80/100, Train Loss: 0.0037\n",
      "LSTM Epoch 90/100, Train Loss: 0.0036\n",
      "LSTM Epoch 100/100, Train Loss: 0.0036\n",
      "Run 8 - LSTM MAE: 0.0461 | RMSE: 0.0649\n",
      "\n",
      "=== Run 9/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0412\n",
      "LSTM Epoch 10/100, Train Loss: 0.0048\n",
      "LSTM Epoch 20/100, Train Loss: 0.0040\n",
      "LSTM Epoch 30/100, Train Loss: 0.0039\n",
      "LSTM Epoch 40/100, Train Loss: 0.0038\n",
      "LSTM Epoch 50/100, Train Loss: 0.0038\n",
      "LSTM Epoch 60/100, Train Loss: 0.0037\n",
      "LSTM Epoch 70/100, Train Loss: 0.0036\n",
      "LSTM Epoch 80/100, Train Loss: 0.0037\n",
      "LSTM Epoch 90/100, Train Loss: 0.0036\n",
      "LSTM Epoch 100/100, Train Loss: 0.0037\n",
      "Run 9 - LSTM MAE: 0.0485 | RMSE: 0.0649\n",
      "\n",
      "=== Run 10/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0360\n",
      "LSTM Epoch 10/100, Train Loss: 0.0048\n",
      "LSTM Epoch 20/100, Train Loss: 0.0042\n",
      "LSTM Epoch 30/100, Train Loss: 0.0039\n",
      "LSTM Epoch 40/100, Train Loss: 0.0039\n",
      "LSTM Epoch 50/100, Train Loss: 0.0040\n",
      "LSTM Epoch 60/100, Train Loss: 0.0037\n",
      "LSTM Epoch 70/100, Train Loss: 0.0037\n",
      "LSTM Epoch 80/100, Train Loss: 0.0040\n",
      "LSTM Epoch 90/100, Train Loss: 0.0039\n",
      "LSTM Epoch 100/100, Train Loss: 0.0036\n",
      "Run 10 - LSTM MAE: 0.0460 | RMSE: 0.0651\n",
      "\n",
      "======= FINAL RESULTS =======\n",
      "Mean LSTM MAE  : 0.0464\n",
      "Mean LSTM RMSE : 0.0649\n"
     ]
    }
   ],
   "source": [
    "# Lists to store metrics for all runs\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for run in range(10):\n",
    "    print(f\"\\n=== Run {run+1}/10 ===\")\n",
    "\n",
    "    # Initialize model\n",
    "    lstm_model = LSTMModel(input_dim=1, hidden_dim=32, seq_len=seq_len)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lstm_model = lstm_model.to(device)\n",
    "\n",
    "    optimizer_lstm = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    num_epochs = 100\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        lstm_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer_lstm.zero_grad()\n",
    "            y_pred = lstm_model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer_lstm.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"LSTM Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    lstm_model.eval()\n",
    "    lstm_preds = []\n",
    "    lstm_targets = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_pred = lstm_model(x_batch)\n",
    "            lstm_preds.append(y_pred.cpu())\n",
    "            lstm_targets.append(y_batch.cpu())\n",
    "\n",
    "    lstm_preds = torch.cat(lstm_preds).squeeze().numpy()\n",
    "    lstm_targets = torch.cat(lstm_targets).squeeze().numpy()\n",
    "\n",
    "    lstm_mae = mean_absolute_error(lstm_targets, lstm_preds)\n",
    "    lstm_rmse = np.sqrt(mean_squared_error(lstm_targets, lstm_preds))\n",
    "\n",
    "    mae_list.append(lstm_mae)\n",
    "    rmse_list.append(lstm_rmse)\n",
    "\n",
    "    print(f\"Run {run+1} - LSTM MAE: {lstm_mae:.4f} | RMSE: {lstm_rmse:.4f}\")\n",
    "\n",
    "# Compute mean metrics\n",
    "mean_lstm_mae = np.mean(mae_list)\n",
    "mean_lstm_rmse = np.mean(rmse_list)\n",
    "\n",
    "print(\"\\n======= FINAL RESULTS =======\")\n",
    "print(f\"Mean LSTM MAE  : {mean_lstm_mae:.4f}\")\n",
    "print(f\"Mean LSTM RMSE : {mean_lstm_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c619a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ce4039a",
   "metadata": {},
   "source": [
    "## AR(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad57096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1000, Test size: 1000\n",
      "Estimated phi coefficients (AR(6)): [0.0361 0.055  0.1245 0.1148 0.1265 0.526 ]\n",
      "Test MAE (AR(p)): 0.0465\n",
      "Test RMSE (AR(p)): 0.0652\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('data/Sunspots_clean.csv')  \n",
    "values = df['Sunspots'].values\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split into training and test sets\n",
    "train_set = scaled_series[:1000]\n",
    "test_set = scaled_series[1000:2000]\n",
    "\n",
    "print (f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "\n",
    "# Prepare AR(p) design matrix for training\n",
    "p = 6  # AR order\n",
    "T_train = len(train_set)\n",
    "\n",
    "# Create lagged input matrix (shape: [T - p, p])\n",
    "X_train = np.column_stack([train_set[i:T_train - p + i] for i in range(p)])\n",
    "y_train = train_set[p:]\n",
    "\n",
    "# Solve OLS: phi = (X^T X)^{-1} X^T y\n",
    "phi_hat = np.linalg.inv(X_train.T @ X_train) @ (X_train.T @ y_train)\n",
    "\n",
    "print(f\"Estimated phi coefficients (AR({p})): {phi_hat.round(4)}\")\n",
    "\n",
    "# 4. Predict on test set\n",
    "# Start with last p values of training set\n",
    "prev_vals = list(train_set[-p:])\n",
    "preds = []\n",
    "\n",
    "for t in range(len(test_set)):\n",
    "    x_input = np.array(prev_vals[-p:])  # most recent 6 values\n",
    "    x_hat = np.dot(phi_hat, x_input)\n",
    "    preds.append(x_hat)\n",
    "    prev_vals.append(test_set[t])  # update with true value (for one-step-ahead)\n",
    "\n",
    "# 5. Compute MAE and RMSE\n",
    "ar_mae = np.mean(np.abs(test_set - preds))\n",
    "ar_rmse = np.sqrt(mean_squared_error(test_set, preds))\n",
    "print(f\"Test MAE (AR(p)): {ar_mae:.4f}\")\n",
    "print(f\"Test RMSE (AR(p)): {ar_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a40d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIB-GRU MAE: 0.0469 | RMSE: 0.0655\n",
      "iproj MAE  : 0.0470 | RMSE: 0.0657\n",
      "LSTM MAE   : 0.0464 | RMSE: 0.0649\n",
      "AR(p) MAE  : 0.0465 | RMSE: 0.0652\n"
     ]
    }
   ],
   "source": [
    "# Compare model \n",
    "print(f\"RIB-GRU MAE: {mean_rib_gru_mae:.4f} | RMSE: {mean_rib_gru_rmse:.4f}\")\n",
    "print(f\"iproj MAE  : {mean_iproj_mae:.4f} | RMSE: {mean_iproj_rmse:.4f}\")\n",
    "print(f\"LSTM MAE   : {mean_lstm_mae:.4f} | RMSE: {mean_lstm_rmse:.4f}\")\n",
    "print(f\"AR(p) MAE  : {ar_mae:.4f} | RMSE: {ar_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f028f",
   "metadata": {},
   "source": [
    "# Data Type II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3425d7",
   "metadata": {},
   "source": [
    "## IB-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e502eeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2612, Test size: 653\n",
      "Epoch 1/1000 | Train Loss: 0.9967\n",
      "Epoch 100/1000 | Train Loss: -0.3437\n",
      "Epoch 200/1000 | Train Loss: -0.4719\n",
      "Epoch 300/1000 | Train Loss: -1.1600\n",
      "Epoch 400/1000 | Train Loss: -1.2661\n",
      "Epoch 500/1000 | Train Loss: -1.3551\n",
      "Epoch 600/1000 | Train Loss: -1.4462\n",
      "Epoch 700/1000 | Train Loss: -1.4515\n",
      "Epoch 800/1000 | Train Loss: -1.4584\n",
      "Epoch 900/1000 | Train Loss: -1.4906\n",
      "Epoch 1000/1000 | Train Loss: -1.5108\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('RIB Paper/data/Sunspots.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.rename(columns={'Monthly Mean Total Sunspot Number': 'Sunspots'}, inplace=True)\n",
    "values = df['Sunspots'].values\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split into training and test sets\n",
    "n = len(scaled_series) * 0.8\n",
    "train_set = scaled_series[:int(n)]\n",
    "test_set = scaled_series[int(n):]\n",
    "\n",
    "print (f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "\n",
    "# Ensure the sequences are of the same length\n",
    "X_train = torch.tensor(train_set[:-1]).unsqueeze(0).float()  \n",
    "Y_train = torch.tensor(train_set[1:]).unsqueeze(0).float()   \n",
    "\n",
    "X_val = torch.tensor(test_set[:-1]).unsqueeze(0).float()\n",
    "Y_val = torch.tensor(test_set[1:]).unsqueeze(0).float()\n",
    "\n",
    "# Create DataLoader for training and validation sets\n",
    "train_loader = DataLoader(TensorDataset(X_train, Y_train), batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, Y_val), batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "rib_gru_model = RIB_GRU_Model(input_dim=1, hidden_dim=32, z_dim=16)\n",
    "optimizer = optim.Adam(rib_gru_model.parameters(), lr=0.001)\n",
    "beta = 0.005\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    rib_gru_model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        h_t = torch.zeros(X_batch.size(0), rib_gru_model.hidden_dim)\n",
    "\n",
    "        loss = 0.0\n",
    "        for t in range(X_batch.size(1)):\n",
    "            x_t = X_batch[:, t].unsqueeze(-1)\n",
    "            y_t = Y_batch[:, t].unsqueeze(-1)\n",
    "\n",
    "            out = rib_gru_model(x_t, h_t)\n",
    "            h_t = out['h_t']\n",
    "\n",
    "            # Compute loss\n",
    "            loss += rib_loss(out, y_t, beta=beta)\n",
    "            \n",
    "        # Average loss over the batch\n",
    "        loss /= X_batch.size(1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    if (epoch + 1) % 100 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#13mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4750093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: RIB-GRU MAE: 0.0424 | RMSE: 0.0566\n",
      "Run 2: RIB-GRU MAE: 0.0427 | RMSE: 0.0573\n",
      "Run 3: RIB-GRU MAE: 0.0424 | RMSE: 0.0561\n",
      "Run 4: RIB-GRU MAE: 0.0425 | RMSE: 0.0568\n",
      "Run 5: RIB-GRU MAE: 0.0426 | RMSE: 0.0568\n",
      "Run 6: RIB-GRU MAE: 0.0423 | RMSE: 0.0568\n",
      "Run 7: RIB-GRU MAE: 0.0420 | RMSE: 0.0562\n",
      "Run 8: RIB-GRU MAE: 0.0422 | RMSE: 0.0566\n",
      "Run 9: RIB-GRU MAE: 0.0425 | RMSE: 0.0567\n",
      "Run 10: RIB-GRU MAE: 0.0422 | RMSE: 0.0566\n",
      "======= FINAL RESULTS =======\n",
      "Mean RIB-GRU MAE: 0.0424 | RMSE: 0.0567\n"
     ]
    }
   ],
   "source": [
    "# Store metrics from all runs\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for run in range(10):\n",
    "\n",
    "    # Validation\n",
    "    rib_gru_model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    vars_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "\n",
    "            h_t = torch.zeros(X_batch.size(0), rib_gru_model.hidden_dim)\n",
    "            pred_mu = []\n",
    "            pred_var = []\n",
    "\n",
    "            for t in range(X_batch.size(1)):\n",
    "\n",
    "                x_t = X_batch[:, t].unsqueeze(-1)\n",
    "                y_t = Y_batch[:, t].unsqueeze(-1)\n",
    "\n",
    "                out = rib_gru_model(x_t, h_t)\n",
    "                h_t = out['h_t']\n",
    "\n",
    "                mu_dec = out['mu_dec']\n",
    "                logvar_dec = out['logvar_dec']\n",
    "\n",
    "                pred_mu.append(mu_dec.squeeze(-1))\n",
    "                pred_var.append(torch.exp(logvar_dec).squeeze(-1))\n",
    "\n",
    "            pred_mu = torch.stack(pred_mu, dim=1)  # [1, T]\n",
    "            pred_var = torch.stack(pred_var, dim=1)  # [1, T]\n",
    "\n",
    "            preds.append(pred_mu)\n",
    "            vars_all.append(pred_var)\n",
    "            trues.append(Y_batch)\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).squeeze(0).numpy()\n",
    "    trues = torch.cat(trues, dim=0).squeeze(0).numpy()\n",
    "    vars_all = torch.cat(vars_all, dim=0).squeeze(0).numpy()\n",
    "\n",
    "    # Calculate MAE, RMSE\n",
    "    rib_gru_mae = np.mean(np.abs(preds - trues))\n",
    "    rib_gru_rmse = np.sqrt(np.mean((preds - trues)**2))\n",
    "\n",
    "    mae_list.append(rib_gru_mae)\n",
    "    rmse_list.append(rib_gru_rmse)\n",
    "\n",
    "    print(f\"Run {run+1}: RIB-GRU MAE: {rib_gru_mae:.4f} | RMSE: {rib_gru_rmse:.4f}\")\n",
    "\n",
    "# Compute mean metrics\n",
    "mean_rib_gru_mae = np.mean(mae_list)\n",
    "mean_rib_gru_rmse = np.mean(rmse_list)\n",
    "\n",
    "print(\"======= FINAL RESULTS =======\")\n",
    "print(f\"Mean RIB-GRU MAE: {mean_rib_gru_mae:.4f} | RMSE: {mean_rib_gru_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9388db72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35b9d18c",
   "metadata": {},
   "source": [
    "## IProjLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e2898a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2612, Test size: 653\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('RIB Paper/data/Sunspots.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.rename(columns={'Monthly Mean Total Sunspot Number': 'Sunspots'}, inplace=True)\n",
    "values = df['Sunspots'].values\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split into training and test sets\n",
    "n = len(scaled_series) * 0.8\n",
    "train_set = scaled_series[:int(n)]\n",
    "test_set = scaled_series[int(n):]\n",
    "\n",
    "print (f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "\n",
    "# Dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, series, seq_len=20): \n",
    "        self.series = torch.tensor(series, dtype=torch.float32)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.series) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.series[idx:idx+self.seq_len]\n",
    "        y = self.series[idx+self.seq_len]\n",
    "        return x.unsqueeze(-1), y.unsqueeze(-1)\n",
    "\n",
    "# Parameters\n",
    "seq_len = 16\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = TimeSeriesDataset(train_set, seq_len)\n",
    "test_dataset = TimeSeriesDataset(test_set, seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94237e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0128\n",
      "Epoch 10/100, Train Loss: 0.0041\n",
      "Epoch 20/100, Train Loss: 0.0041\n",
      "Epoch 30/100, Train Loss: 0.0041\n",
      "Epoch 40/100, Train Loss: 0.0041\n",
      "Epoch 50/100, Train Loss: 0.0042\n",
      "Epoch 60/100, Train Loss: 0.0041\n",
      "Epoch 70/100, Train Loss: 0.0040\n",
      "Epoch 80/100, Train Loss: 0.0040\n",
      "Epoch 90/100, Train Loss: 0.0039\n",
      "Epoch 100/100, Train Loss: 0.0039\n",
      "Run 1 - Test MAE: 0.0403 | Test RMSE: 0.0563\n",
      "\n",
      "=== Run 2/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0081\n",
      "Epoch 10/100, Train Loss: 0.0041\n",
      "Epoch 20/100, Train Loss: 0.0041\n",
      "Epoch 30/100, Train Loss: 0.0042\n",
      "Epoch 40/100, Train Loss: 0.0041\n",
      "Epoch 50/100, Train Loss: 0.0041\n",
      "Epoch 60/100, Train Loss: 0.0042\n",
      "Epoch 70/100, Train Loss: 0.0040\n",
      "Epoch 80/100, Train Loss: 0.0039\n",
      "Epoch 90/100, Train Loss: 0.0040\n",
      "Epoch 100/100, Train Loss: 0.0041\n",
      "Run 2 - Test MAE: 0.0423 | Test RMSE: 0.0565\n",
      "\n",
      "=== Run 3/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0433\n",
      "Epoch 10/100, Train Loss: 0.0042\n",
      "Epoch 20/100, Train Loss: 0.0042\n",
      "Epoch 30/100, Train Loss: 0.0044\n",
      "Epoch 40/100, Train Loss: 0.0042\n",
      "Epoch 50/100, Train Loss: 0.0041\n",
      "Epoch 60/100, Train Loss: 0.0041\n",
      "Epoch 70/100, Train Loss: 0.0041\n",
      "Epoch 80/100, Train Loss: 0.0041\n",
      "Epoch 90/100, Train Loss: 0.0040\n",
      "Epoch 100/100, Train Loss: 0.0040\n",
      "Run 3 - Test MAE: 0.0404 | Test RMSE: 0.0560\n",
      "\n",
      "=== Run 4/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0066\n",
      "Epoch 10/100, Train Loss: 0.0042\n",
      "Epoch 20/100, Train Loss: 0.0044\n",
      "Epoch 30/100, Train Loss: 0.0041\n",
      "Epoch 40/100, Train Loss: 0.0042\n",
      "Epoch 50/100, Train Loss: 0.0040\n",
      "Epoch 60/100, Train Loss: 0.0040\n",
      "Epoch 70/100, Train Loss: 0.0039\n",
      "Epoch 80/100, Train Loss: 0.0039\n",
      "Epoch 90/100, Train Loss: 0.0039\n",
      "Epoch 100/100, Train Loss: 0.0040\n",
      "Run 4 - Test MAE: 0.0414 | Test RMSE: 0.0571\n",
      "\n",
      "=== Run 5/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0165\n",
      "Epoch 10/100, Train Loss: 0.0042\n",
      "Epoch 20/100, Train Loss: 0.0042\n",
      "Epoch 30/100, Train Loss: 0.0043\n",
      "Epoch 40/100, Train Loss: 0.0041\n",
      "Epoch 50/100, Train Loss: 0.0041\n",
      "Epoch 60/100, Train Loss: 0.0040\n",
      "Epoch 70/100, Train Loss: 0.0040\n",
      "Epoch 80/100, Train Loss: 0.0039\n",
      "Epoch 90/100, Train Loss: 0.0041\n",
      "Epoch 100/100, Train Loss: 0.0039\n",
      "Run 5 - Test MAE: 0.0405 | Test RMSE: 0.0558\n",
      "\n",
      "=== Run 6/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0110\n",
      "Epoch 10/100, Train Loss: 0.0041\n",
      "Epoch 20/100, Train Loss: 0.0041\n",
      "Epoch 30/100, Train Loss: 0.0041\n",
      "Epoch 40/100, Train Loss: 0.0041\n",
      "Epoch 50/100, Train Loss: 0.0041\n",
      "Epoch 60/100, Train Loss: 0.0040\n",
      "Epoch 70/100, Train Loss: 0.0041\n",
      "Epoch 80/100, Train Loss: 0.0039\n",
      "Epoch 90/100, Train Loss: 0.0039\n",
      "Epoch 100/100, Train Loss: 0.0040\n",
      "Run 6 - Test MAE: 0.0413 | Test RMSE: 0.0564\n",
      "\n",
      "=== Run 7/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0525\n",
      "Epoch 10/100, Train Loss: 0.0043\n",
      "Epoch 20/100, Train Loss: 0.0042\n",
      "Epoch 30/100, Train Loss: 0.0041\n",
      "Epoch 40/100, Train Loss: 0.0041\n",
      "Epoch 50/100, Train Loss: 0.0042\n",
      "Epoch 60/100, Train Loss: 0.0042\n",
      "Epoch 70/100, Train Loss: 0.0046\n",
      "Epoch 80/100, Train Loss: 0.0041\n",
      "Epoch 90/100, Train Loss: 0.0041\n",
      "Epoch 100/100, Train Loss: 0.0039\n",
      "Run 7 - Test MAE: 0.0428 | Test RMSE: 0.0568\n",
      "\n",
      "=== Run 8/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0253\n",
      "Epoch 10/100, Train Loss: 0.0043\n",
      "Epoch 20/100, Train Loss: 0.0042\n",
      "Epoch 30/100, Train Loss: 0.0042\n",
      "Epoch 40/100, Train Loss: 0.0041\n",
      "Epoch 50/100, Train Loss: 0.0041\n",
      "Epoch 60/100, Train Loss: 0.0041\n",
      "Epoch 70/100, Train Loss: 0.0041\n",
      "Epoch 80/100, Train Loss: 0.0042\n",
      "Epoch 90/100, Train Loss: 0.0041\n",
      "Epoch 100/100, Train Loss: 0.0040\n",
      "Run 8 - Test MAE: 0.0406 | Test RMSE: 0.0561\n",
      "\n",
      "=== Run 9/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0062\n",
      "Epoch 10/100, Train Loss: 0.0041\n",
      "Epoch 20/100, Train Loss: 0.0042\n",
      "Epoch 30/100, Train Loss: 0.0042\n",
      "Epoch 40/100, Train Loss: 0.0043\n",
      "Epoch 50/100, Train Loss: 0.0041\n",
      "Epoch 60/100, Train Loss: 0.0041\n",
      "Epoch 70/100, Train Loss: 0.0040\n",
      "Epoch 80/100, Train Loss: 0.0039\n",
      "Epoch 90/100, Train Loss: 0.0039\n",
      "Epoch 100/100, Train Loss: 0.0039\n",
      "Run 9 - Test MAE: 0.0411 | Test RMSE: 0.0564\n",
      "\n",
      "=== Run 10/10 ===\n",
      "Epoch 1/100, Train Loss: 0.0218\n",
      "Epoch 10/100, Train Loss: 0.0042\n",
      "Epoch 20/100, Train Loss: 0.0041\n",
      "Epoch 30/100, Train Loss: 0.0041\n",
      "Epoch 40/100, Train Loss: 0.0041\n",
      "Epoch 50/100, Train Loss: 0.0042\n",
      "Epoch 60/100, Train Loss: 0.0043\n",
      "Epoch 70/100, Train Loss: 0.0042\n",
      "Epoch 80/100, Train Loss: 0.0041\n",
      "Epoch 90/100, Train Loss: 0.0040\n",
      "Epoch 100/100, Train Loss: 0.0039\n",
      "Run 10 - Test MAE: 0.0416 | Test RMSE: 0.0565\n",
      "\n",
      "======= FINAL RESULTS =======\n",
      "Mean MAE  : 0.0412\n",
      "Mean RMSE : 0.0564\n"
     ]
    }
   ],
   "source": [
    "# Lists to store metrics for all runs\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for run in range(10):\n",
    "    print(f\"\\n=== Run {run+1}/10 ===\")\n",
    "\n",
    "    # Model setup\n",
    "    iproj_model = IProjLSTMModel(input_dim=1, hidden_dim=32, seq_len=seq_len)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    iproj_model = iproj_model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(iproj_model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        iproj_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = iproj_model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    iproj_model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_pred = iproj_model(x_batch)\n",
    "            preds.append(y_pred.cpu())\n",
    "            targets.append(y_batch.cpu())\n",
    "\n",
    "    preds = torch.cat(preds).squeeze().numpy()\n",
    "    targets = torch.cat(targets).squeeze().numpy()\n",
    "\n",
    "    iproj_mae = mean_absolute_error(targets, preds)\n",
    "    iproj_rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "\n",
    "    mae_list.append(iproj_mae)\n",
    "    rmse_list.append(iproj_rmse)\n",
    "\n",
    "    print(f\"Run {run+1} - Test MAE: {iproj_mae:.4f} | Test RMSE: {iproj_rmse:.4f}\")\n",
    "\n",
    "# Compute mean metrics\n",
    "mean_iproj_mae = np.mean(mae_list)\n",
    "mean_iproj_rmse = np.mean(rmse_list)\n",
    "\n",
    "print(\"\\n======= FINAL RESULTS =======\")\n",
    "print(f\"Mean MAE  : {mean_iproj_mae:.4f}\")\n",
    "print(f\"Mean RMSE : {mean_iproj_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711d2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "443114cf",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92778cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2612, Test size: 653\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('RIB Paper/data/Sunspots.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.rename(columns={'Monthly Mean Total Sunspot Number': 'Sunspots'}, inplace=True)\n",
    "values = df['Sunspots'].values\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split into training and test sets\n",
    "n = len(scaled_series) * 0.8\n",
    "train_set = scaled_series[:int(n)]\n",
    "test_set = scaled_series[int(n):]\n",
    "\n",
    "print (f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "\n",
    "# Dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, series, seq_len=20): \n",
    "        self.series = torch.tensor(series, dtype=torch.float32)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.series) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.series[idx:idx+self.seq_len]\n",
    "        y = self.series[idx+self.seq_len]\n",
    "        return x.unsqueeze(-1), y.unsqueeze(-1)\n",
    "\n",
    "# Parameters\n",
    "seq_len = 16\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = TimeSeriesDataset(train_set, seq_len)\n",
    "test_dataset = TimeSeriesDataset(test_set, seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c448379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run 1/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0450\n",
      "LSTM Epoch 10/100, Train Loss: 0.0046\n",
      "LSTM Epoch 20/100, Train Loss: 0.0042\n",
      "LSTM Epoch 30/100, Train Loss: 0.0042\n",
      "LSTM Epoch 40/100, Train Loss: 0.0040\n",
      "LSTM Epoch 50/100, Train Loss: 0.0040\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0041\n",
      "LSTM Epoch 80/100, Train Loss: 0.0040\n",
      "LSTM Epoch 90/100, Train Loss: 0.0040\n",
      "LSTM Epoch 100/100, Train Loss: 0.0039\n",
      "Run 1 - LSTM MAE: 0.0408 | RMSE: 0.0562\n",
      "\n",
      "=== Run 2/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0220\n",
      "LSTM Epoch 10/100, Train Loss: 0.0044\n",
      "LSTM Epoch 20/100, Train Loss: 0.0043\n",
      "LSTM Epoch 30/100, Train Loss: 0.0041\n",
      "LSTM Epoch 40/100, Train Loss: 0.0040\n",
      "LSTM Epoch 50/100, Train Loss: 0.0040\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0041\n",
      "LSTM Epoch 80/100, Train Loss: 0.0040\n",
      "LSTM Epoch 90/100, Train Loss: 0.0040\n",
      "LSTM Epoch 100/100, Train Loss: 0.0039\n",
      "Run 2 - LSTM MAE: 0.0405 | RMSE: 0.0559\n",
      "\n",
      "=== Run 3/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0325\n",
      "LSTM Epoch 10/100, Train Loss: 0.0045\n",
      "LSTM Epoch 20/100, Train Loss: 0.0042\n",
      "LSTM Epoch 30/100, Train Loss: 0.0040\n",
      "LSTM Epoch 40/100, Train Loss: 0.0040\n",
      "LSTM Epoch 50/100, Train Loss: 0.0042\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0040\n",
      "LSTM Epoch 80/100, Train Loss: 0.0040\n",
      "LSTM Epoch 90/100, Train Loss: 0.0039\n",
      "LSTM Epoch 100/100, Train Loss: 0.0039\n",
      "Run 3 - LSTM MAE: 0.0408 | RMSE: 0.0570\n",
      "\n",
      "=== Run 4/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0328\n",
      "LSTM Epoch 10/100, Train Loss: 0.0046\n",
      "LSTM Epoch 20/100, Train Loss: 0.0042\n",
      "LSTM Epoch 30/100, Train Loss: 0.0040\n",
      "LSTM Epoch 40/100, Train Loss: 0.0041\n",
      "LSTM Epoch 50/100, Train Loss: 0.0040\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0039\n",
      "LSTM Epoch 80/100, Train Loss: 0.0040\n",
      "LSTM Epoch 90/100, Train Loss: 0.0039\n",
      "LSTM Epoch 100/100, Train Loss: 0.0040\n",
      "Run 4 - LSTM MAE: 0.0425 | RMSE: 0.0570\n",
      "\n",
      "=== Run 5/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0586\n",
      "LSTM Epoch 10/100, Train Loss: 0.0047\n",
      "LSTM Epoch 20/100, Train Loss: 0.0043\n",
      "LSTM Epoch 30/100, Train Loss: 0.0042\n",
      "LSTM Epoch 40/100, Train Loss: 0.0041\n",
      "LSTM Epoch 50/100, Train Loss: 0.0041\n",
      "LSTM Epoch 60/100, Train Loss: 0.0041\n",
      "LSTM Epoch 70/100, Train Loss: 0.0041\n",
      "LSTM Epoch 80/100, Train Loss: 0.0040\n",
      "LSTM Epoch 90/100, Train Loss: 0.0039\n",
      "LSTM Epoch 100/100, Train Loss: 0.0039\n",
      "Run 5 - LSTM MAE: 0.0412 | RMSE: 0.0563\n",
      "\n",
      "=== Run 6/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0213\n",
      "LSTM Epoch 10/100, Train Loss: 0.0044\n",
      "LSTM Epoch 20/100, Train Loss: 0.0043\n",
      "LSTM Epoch 30/100, Train Loss: 0.0041\n",
      "LSTM Epoch 40/100, Train Loss: 0.0041\n",
      "LSTM Epoch 50/100, Train Loss: 0.0040\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0040\n",
      "LSTM Epoch 80/100, Train Loss: 0.0039\n",
      "LSTM Epoch 90/100, Train Loss: 0.0040\n",
      "LSTM Epoch 100/100, Train Loss: 0.0040\n",
      "Run 6 - LSTM MAE: 0.0423 | RMSE: 0.0571\n",
      "\n",
      "=== Run 7/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0304\n",
      "LSTM Epoch 10/100, Train Loss: 0.0046\n",
      "LSTM Epoch 20/100, Train Loss: 0.0042\n",
      "LSTM Epoch 30/100, Train Loss: 0.0041\n",
      "LSTM Epoch 40/100, Train Loss: 0.0041\n",
      "LSTM Epoch 50/100, Train Loss: 0.0043\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0040\n",
      "LSTM Epoch 80/100, Train Loss: 0.0039\n",
      "LSTM Epoch 90/100, Train Loss: 0.0039\n",
      "LSTM Epoch 100/100, Train Loss: 0.0044\n",
      "Run 7 - LSTM MAE: 0.0421 | RMSE: 0.0572\n",
      "\n",
      "=== Run 8/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0328\n",
      "LSTM Epoch 10/100, Train Loss: 0.0045\n",
      "LSTM Epoch 20/100, Train Loss: 0.0041\n",
      "LSTM Epoch 30/100, Train Loss: 0.0041\n",
      "LSTM Epoch 40/100, Train Loss: 0.0041\n",
      "LSTM Epoch 50/100, Train Loss: 0.0042\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0040\n",
      "LSTM Epoch 80/100, Train Loss: 0.0040\n",
      "LSTM Epoch 90/100, Train Loss: 0.0040\n",
      "LSTM Epoch 100/100, Train Loss: 0.0040\n",
      "Run 8 - LSTM MAE: 0.0423 | RMSE: 0.0567\n",
      "\n",
      "=== Run 9/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0196\n",
      "LSTM Epoch 10/100, Train Loss: 0.0045\n",
      "LSTM Epoch 20/100, Train Loss: 0.0041\n",
      "LSTM Epoch 30/100, Train Loss: 0.0040\n",
      "LSTM Epoch 40/100, Train Loss: 0.0040\n",
      "LSTM Epoch 50/100, Train Loss: 0.0042\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0039\n",
      "LSTM Epoch 80/100, Train Loss: 0.0039\n",
      "LSTM Epoch 90/100, Train Loss: 0.0039\n",
      "LSTM Epoch 100/100, Train Loss: 0.0039\n",
      "Run 9 - LSTM MAE: 0.0407 | RMSE: 0.0561\n",
      "\n",
      "=== Run 10/10 ===\n",
      "LSTM Epoch 1/100, Train Loss: 0.0207\n",
      "LSTM Epoch 10/100, Train Loss: 0.0045\n",
      "LSTM Epoch 20/100, Train Loss: 0.0042\n",
      "LSTM Epoch 30/100, Train Loss: 0.0040\n",
      "LSTM Epoch 40/100, Train Loss: 0.0040\n",
      "LSTM Epoch 50/100, Train Loss: 0.0040\n",
      "LSTM Epoch 60/100, Train Loss: 0.0040\n",
      "LSTM Epoch 70/100, Train Loss: 0.0040\n",
      "LSTM Epoch 80/100, Train Loss: 0.0039\n",
      "LSTM Epoch 90/100, Train Loss: 0.0039\n",
      "LSTM Epoch 100/100, Train Loss: 0.0041\n",
      "Run 10 - LSTM MAE: 0.0423 | RMSE: 0.0566\n",
      "\n",
      "======= FINAL RESULTS =======\n",
      "Mean LSTM MAE  : 0.0415\n",
      "Mean LSTM RMSE : 0.0566\n"
     ]
    }
   ],
   "source": [
    "# Lists to store metrics for all runs\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for run in range(10):\n",
    "    print(f\"\\n=== Run {run+1}/10 ===\")\n",
    "\n",
    "    # Initialize model\n",
    "    lstm_model = LSTMModel(input_dim=1, hidden_dim=32, seq_len=seq_len)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    lstm_model = lstm_model.to(device)\n",
    "\n",
    "    optimizer_lstm = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    num_epochs = 100\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        lstm_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer_lstm.zero_grad()\n",
    "            y_pred = lstm_model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer_lstm.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "        if (epoch+1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"LSTM Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    lstm_model.eval()\n",
    "    lstm_preds = []\n",
    "    lstm_targets = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_pred = lstm_model(x_batch)\n",
    "            lstm_preds.append(y_pred.cpu())\n",
    "            lstm_targets.append(y_batch.cpu())\n",
    "\n",
    "    lstm_preds = torch.cat(lstm_preds).squeeze().numpy()\n",
    "    lstm_targets = torch.cat(lstm_targets).squeeze().numpy()\n",
    "\n",
    "    lstm_mae = mean_absolute_error(lstm_targets, lstm_preds)\n",
    "    lstm_rmse = np.sqrt(mean_squared_error(lstm_targets, lstm_preds))\n",
    "\n",
    "    mae_list.append(lstm_mae)\n",
    "    rmse_list.append(lstm_rmse)\n",
    "\n",
    "    print(f\"Run {run+1} - LSTM MAE: {lstm_mae:.4f} | RMSE: {lstm_rmse:.4f}\")\n",
    "\n",
    "# Compute mean metrics\n",
    "mean_lstm_mae = np.mean(mae_list)\n",
    "mean_lstm_rmse = np.mean(rmse_list)\n",
    "\n",
    "print(\"\\n======= FINAL RESULTS =======\")\n",
    "print(f\"Mean LSTM MAE  : {mean_lstm_mae:.4f}\")\n",
    "print(f\"Mean LSTM RMSE : {mean_lstm_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a916be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1932ba44",
   "metadata": {},
   "source": [
    "## AR(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba9a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2612, Test size: 653\n",
      "Estimated phi coefficients (AR(6)): [0.0759 0.095  0.1028 0.1245 0.5855]\n",
      "Test MAE (AR(6)): 0.0419\n",
      "Test RMSE (AR(6)): 0.0579\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('RIB Paper/data/Sunspots.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.rename(columns={'Monthly Mean Total Sunspot Number': 'Sunspots'}, inplace=True)\n",
    "values = df['Sunspots'].values\n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_series = scaler.fit_transform(values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split into training and test sets\n",
    "n = len(scaled_series) * 0.8\n",
    "train_set = scaled_series[:int(n)]\n",
    "test_set = scaled_series[int(n):]\n",
    "\n",
    "print (f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "\n",
    "# Prepare AR(6) design matrix for training\n",
    "p = 5  # AR order\n",
    "T_train = len(train_set)\n",
    "\n",
    "# Create lagged input matrix (shape: [T - p, p])\n",
    "X_train = np.column_stack([train_set[i:T_train - p + i] for i in range(p)])\n",
    "y_train = train_set[p:]\n",
    "\n",
    "# Solve OLS: phi = (X^T X)^{-1} X^T y\n",
    "phi_hat = np.linalg.inv(X_train.T @ X_train) @ (X_train.T @ y_train)\n",
    "\n",
    "print(f\"Estimated phi coefficients (AR(p)): {phi_hat.round(4)}\")\n",
    "\n",
    "# 4. Predict on test set\n",
    "# Start with last p values of training set\n",
    "prev_vals = list(train_set[-p:])\n",
    "preds = []\n",
    "\n",
    "for t in range(len(test_set)):\n",
    "    x_input = np.array(prev_vals[-p:])  # most recent 6 values\n",
    "    x_hat = np.dot(phi_hat, x_input)\n",
    "    preds.append(x_hat)\n",
    "    prev_vals.append(test_set[t])  # update with true value (for one-step-ahead)\n",
    "\n",
    "# 5. Compute MAE and RMSE\n",
    "ar_mae = np.mean(np.abs(test_set - preds))\n",
    "ar_rmse = np.sqrt(mean_squared_error(test_set, preds))\n",
    "print(f\"Test MAE (AR(p)): {ar_mae:.4f}\")\n",
    "print(f\"Test RMSE (AR(6\\p)): {ar_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede28cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04546106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIB-GRU MAE:   0.0424 | RMSE: 0.0567\n",
      "IProjLSTM MAE: 0.0412 | RMSE: 0.0564\n",
      "LSTM MAE:      0.0415 | RMSE: 0.0566\n",
      "AR(p) MAE:     0.0419 | RMSE: 0.0579\n"
     ]
    }
   ],
   "source": [
    "# Compare results of these 3 model\n",
    "print(f\"RIB-GRU MAE:   {mean_rib_gru_mae:.4f} | RMSE: {mean_rib_gru_rmse:.4f}\")\n",
    "print(f\"IProjLSTM MAE: {mean_iproj_mae:.4f} | RMSE: {mean_iproj_rmse:.4f}\")\n",
    "print(f\"LSTM MAE:      {mean_lstm_mae:.4f} | RMSE: {mean_lstm_rmse:.4f}\")\n",
    "print(f\"AR(p) MAE:     {ar_mae:.4f} | RMSE: {ar_rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
